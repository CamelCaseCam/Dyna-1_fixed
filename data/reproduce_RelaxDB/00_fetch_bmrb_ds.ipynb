{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bb236b-1f91-4498-90dd-ec1060c74e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper')\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/wayment/software')\n",
    "import pynmrstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd435eab-1139-4f19-8e6e-542b58519e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BMRB_T1T2NOE_set_aug92024update_MANUALLY_CURATED.csv')\n",
    "\n",
    "# last update Dec 9, 2024\n",
    "\n",
    "subset = [4267,4390,4689,4762,5154,5330,5518,5687,5762,5839,5841,5991,5995,6470,6758,6838,7035,7036,7056,7432,11080,15255,15445,15451,15521,15795,16234,\n",
    "          16392,16426,16737,17018,17246,17266,17306,17701,17783,17881,18092,18257,18260,18306,18380,18477,18758,18772,18773,18903,19127,19153,19189,19335,19356,\n",
    "          25013,25636,26513,26723,27011,27194,27888,30523,34545,36171,50020,50233,50332,50410,50734,51087,51230,51416]\n",
    "df = df.loc[df.entry_ID.isin(subset)]\n",
    "\n",
    "seq_diff={18257: 9, 6758: 8, 15445: 8, 15975: 10, 16392: 23, 16737: 6, 17246: 6, 17306: 6, 17701: 6, 17783: 10, 18092: 6, 18477: 8, 27011: 6, 50410: 7,18903: 81}\n",
    "N_or_C={18257: 'N', 6758: 'N', 15445: 'N', 15975: 'N', 16392: 'N', 16737: 'C', 17246: 'C', 17306: 'C', 17701: 'C', 17783: 'N', 18092: 'C', 18477: 'N', 27011: 'C', 50410: 'C',18903: 'C'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7bb0527-6b68-41c8-a40f-8adc1f87a141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset) # Dec 9: 71. Jan 20: 70, removed 28132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4334b268-2f17-4256-80e1-ae23f05e81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units(val, err, unit, pseudo=1e-8):\n",
    "    '''Takes in values and value errors (T1 or T2)\n",
    "    and standardizes them to be rates with units of s-1\n",
    "    \n",
    "    Inputs:\n",
    "    val: list-like, values of T1 or T2 or Rex\n",
    "    err: list-like, values of associated error\n",
    "    unit: str from BMRB entry (s, s-1, Hz, ms-1, ms)\n",
    "    pseudo: pseudocount to avoid dividing by zero\n",
    "    \n",
    "    Outputs:\n",
    "    out: list-like, normalized rate in (s-1) units\n",
    "    out_err, list-like, normalized error on rate in (s-1)\n",
    "    '''\n",
    "    \n",
    "    if unit=='s':\n",
    "        out = 1/val\n",
    "        out_err = out * err/val\n",
    "        return out, out_err\n",
    "    \n",
    "    elif unit == 's-1' or unit == 'Hz':\n",
    "        return val, err\n",
    "\n",
    "    elif unit=='ms-1':\n",
    "        return 1000*val, 1000*err\n",
    "    \n",
    "    elif unit== 'ms':\n",
    "        out = 1/val\n",
    "        out_err = out*err/val\n",
    "        return 1000*out, 1000*out_err\n",
    "    else:\n",
    "        raise runtimeError('Unit type not understood.')\n",
    "\n",
    "\n",
    "def get_data(row, expt_kw='T1_experiment', val_kw='Val', err_kw='Val_err', unit_kw='T1_val_units'):\n",
    "    if pd.isna(row[expt_kw]):\n",
    "        return np.zeros(len(row['sequence']))*np.NaN,np.zeros(len(row['sequence']))*np.NaN \n",
    "    entry = pynmrstar.Entry.from_database(int(row['entry_ID']))\n",
    "    \n",
    "#     if row['entry_ID'] == 19153:\n",
    "#         entry.rename_saveframe('heteronuclear_list_T1_2','heteronuclear_T1_list_2')\n",
    "\n",
    "    loops = entry[row[expt_kw]]._loops\n",
    "    \n",
    "    #Find correct loop\n",
    "    for i, loop in enumerate(loops):\n",
    "        if val_kw in loop._tags:\n",
    "            loop_ind = i\n",
    "            break\n",
    "    loop = loops[loop_ind]\n",
    "    \n",
    "    # initialize arrays\n",
    "    #seq = entry.get_saveframes_by_category('entity')[0]['Polymer_seq_one_letter_code'][0].replace('\\n','')\n",
    "    seq = row['sequence']\n",
    "    T, T_err = np.ones(len(seq))*np.nan, np.ones(len(seq))*np.nan\n",
    "    \n",
    "#    atom_id_lst=[]\n",
    "\n",
    "    # Loop thru data\n",
    "    for i, res in enumerate(loop.data):\n",
    "        T_val = res[loop._tags.index(val_kw)]\n",
    "        T_val_err = res[loop._tags.index(err_kw)]\n",
    "        atom_id = res[loop._tags.index('Atom_ID')] # keeping track of this to remove second peaks for Arg, Trp. Only happens in entry 4267\n",
    "        # if atom_id not in atom_id_lst:\n",
    "        #     atom_id_lst.append(atom_id)\n",
    "        seqpos = int(res[loop._tags.index('Seq_ID')]) - 1 # Zero-indexing seqpos here.\n",
    "        #resname = seq1(res[loop._tags.index('Comp_ID')])\n",
    "\n",
    "        if T_val != '.' and np.isnan(T[seqpos]) and atom_id in ['N','H']: # no value yet, doing this to prevent second sidechain atom\n",
    "            if float(T_val) != 0:\n",
    "                T[seqpos] = float(T_val)\n",
    "                if T_val_err != '.':\n",
    "                    T_err[seqpos] = float(T_val_err)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # convert units\n",
    "    if unit_kw is not None:\n",
    "        unit = entry[row[expt_kw]][unit_kw][0]\n",
    "        if unit=='.':\n",
    "            unit = entry[row[expt_kw]]['T2_val_units'][0]\n",
    "        if row['entry_ID']==5154: unit='s'\n",
    "        if row['entry_ID']==7056: unit='s'\n",
    "        if row['entry_ID']==7088: unit='s'\n",
    "        if row['entry_ID']==15930: unit='s'\n",
    "        if row['entry_ID']==16737: unit='ms'\n",
    "        if row['entry_ID']==17701: unit='ms'\n",
    "        if row['entry_ID']==17266: unit='s-1'\n",
    "        if row['entry_ID']==18087: unit='s-1'\n",
    "        if row['entry_ID']==18758: unit='s-1'\n",
    "        if row['entry_ID']==50734: unit='ms'\n",
    "        if row['entry_ID']==50745: unit='ms'\n",
    "        if row['entry_ID']==51306 and val_kw=='Val': unit='s'\n",
    "        if row['entry_ID']==51306 and val_kw=='T2_val': unit='s-1'\n",
    "        if row['entry_ID']==51478: unit='s-1'\n",
    "        if row['entry_ID']==51126: unit='s-1'\n",
    "        \n",
    "    # 26788 T2 switched column of error and value\n",
    "    # 17266 also switched column of T2 error and value, and stated unit is s for it when it should be s-1\n",
    "    if row['entry_ID'] == 26788 and expt_kw=='T2_experiment':\n",
    "        T, T_err = convert_units(T_err, T, unit)\n",
    "    elif row['entry_ID'] == 17266 and expt_kw=='T2_experiment':\n",
    "        T, T_err = convert_units(T_err, T, unit)\n",
    "    else:\n",
    "        T, T_err = convert_units(T, T_err, unit)\n",
    "        \n",
    "    #27011 flipped error, confirmed this with authors\n",
    "    if row['entry_ID'] ==27011 and expt_kw=='T2_experiment':\n",
    "        T_err = 1/T_err\n",
    "        \n",
    "    # 15486: they deposited T1/T2 in value column and R1/R2 in err column\n",
    "    if row['entry_ID'] == 15486: #or row['entry_ID'] == 17266:\n",
    "        T_err = np.zeros(len(row['sequence']))*np.NaN\n",
    "\n",
    "    # if row['entry_ID']==7036: # deposited seq was different than data seqpos. Fixed in manual csv, should start with \"HVVQ...\"\n",
    "    #     T = T[:-2]\n",
    "    #     T_err = T_err[:-2]\n",
    "            \n",
    "    return T, T_err\n",
    "\n",
    "def get_NOE_data(row, expt_kw='NOE_experiment', val_kw='Val', err_kw='Val_err'):\n",
    "    if pd.isna(row[expt_kw]):\n",
    "        return np.zeros(len(row['sequence']))*np.NaN,np.zeros(len(row['sequence']))*np.NaN \n",
    "    entry = pynmrstar.Entry.from_database(row['entry_ID'])\n",
    "    \n",
    "#     if row['entry_ID'] == 19153:\n",
    "#         entry.rename_saveframe('heteronuclear_list_T1_2','heteronuclear_T1_list_2')\n",
    "\n",
    "    loops = entry[row[expt_kw]]._loops\n",
    "    \n",
    "    #Find correct loop\n",
    "    for i, loop in enumerate(loops):\n",
    "        if val_kw in loop._tags:\n",
    "            loop_ind = i\n",
    "            break\n",
    "    loop = loops[loop_ind]\n",
    "    \n",
    "    # initialize arrays\n",
    "    #seq = entry.get_saveframes_by_category('entity')[0]['Polymer_seq_one_letter_code'][0].replace('\\n','')\n",
    "    seq = row['sequence']\n",
    "    T, T_err = np.ones(len(seq))*np.nan, np.ones(len(seq))*np.nan\n",
    "\n",
    "    # Loop thru data\n",
    "    for i, res in enumerate(loop.data):\n",
    "        T_val = res[loop._tags.index(val_kw)]\n",
    "        T_val_err = res[loop._tags.index(err_kw)]\n",
    "        atom_id = res[loop._tags.index('Atom_ID_1')] # keeping track of this to remove second peaks for Arg, Trp. Only happens in entry 4267\n",
    "        seqpos = int(res[loop._tags.index('Seq_ID_1')]) - 1 # Zero-indexing seqpos here.\n",
    "        #resname = seq1(res[loop._tags.index('Comp_ID')])\n",
    "        \n",
    "        atom_pass=False\n",
    "        if atom_id in ['N','H'] or row['entry_ID'] in [6470, 5330, 5687, 5720]: # these didn't put anything for atom_id\n",
    "            atom_pass=True\n",
    "\n",
    "        if T_val != '.' and np.isnan(T[seqpos]) and atom_pass: # no value yet, doing this to prevent second sidechain atom\n",
    "            if float(T_val) != 0:\n",
    "                T[seqpos] = float(T_val)\n",
    "                if T_val_err != '.':\n",
    "                    T_err[seqpos] = float(T_val_err)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    if row['entry_ID']==18257: # values are reported as relative intensities, not normalized to reference integral\n",
    "        T = np.zeros(214)*np.NaN\n",
    "        T_err = np.zeros(214)*np.NaN\n",
    "        \n",
    "    if row['entry_ID']==19356: \n",
    "        T /= np.nanmax(T)\n",
    "        T_err = np.zeros(88)*np.NaN\n",
    "        \n",
    "    if row['entry_ID']==16737: \n",
    "        T /= np.nanmax(T)   \n",
    "        \n",
    "    return T, T_err\n",
    "\n",
    "df[['R1','R1_err']] = df.apply(lambda row: get_data(row), axis=1, result_type='expand')\n",
    "df[['R2','R2_err']] = df.apply(lambda row: get_data(row,expt_kw='T2_experiment', val_kw='T2_val', err_kw='T2_val_err', unit_kw = 'T2_val_units'), axis=1, result_type='expand')\n",
    "df[['NOE','NOE_err']] = df.apply(lambda row: get_NOE_data(row), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c72396-74fb-49cf-8972-2d9b0d8f4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust(row, MET):\n",
    "    if row['entry_ID'] in seq_diff.keys():\n",
    "        offset=seq_diff[row['entry_ID']]\n",
    "        \n",
    "        if N_or_C[row['entry_ID']]=='N':\n",
    "            return row[MET][offset:], row[MET+'_err'][offset:]\n",
    "        else: \n",
    "            return row[MET][:-1*offset], row[MET+'_err'][:-1*offset]\n",
    "    else:\n",
    "        return row[MET], row[MET+'_err']\n",
    "\n",
    "df[['R1','R1_err']] = df.apply(lambda row: adjust(row, 'R1'), axis=1, result_type='expand')\n",
    "df[['R2','R2_err']] = df.apply(lambda row: adjust(row, 'R2'), axis=1, result_type='expand')\n",
    "df[['NOE','NOE_err']] = df.apply(lambda row: adjust(row, 'NOE'), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc5397f-ed3e-457c-8e81-ce0597562298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7035\n",
      "7036\n",
      "18257\n"
     ]
    }
   ],
   "source": [
    "for ind in [7035, 7036, 18257]:\n",
    "    print(ind)\n",
    "    entry = df.loc[df.entry_ID==ind].iloc[0]\n",
    "    noe = pd.read_csv(f'patched_NOEs/{ind}_NOE.csv')\n",
    "\n",
    "    noe_vec = np.zeros(len(entry['sequence']))*np.NaN\n",
    "    noe_err_vec = np.zeros(len(entry['sequence']))*np.NaN\n",
    "\n",
    "    for _, row in noe.iterrows():\n",
    "        noe_vec[int(row['seqpos']-1)] = row['NOE']\n",
    "        noe_err_vec[int(row['seqpos']-1)] = row['NOE_err']\n",
    "\n",
    "    df.at[entry.name,'NOE'] = noe_vec\n",
    "    df.at[entry.name,'NOE_err'] = noe_err_vec\n",
    "    \n",
    "    df.at[entry.name,'NOE_expt_index']='manual'\n",
    "    \n",
    "df.at[entry.name,'NOE'] = df.at[entry.name,'NOE'][:-9]\n",
    "df.at[entry.name,'NOE_err'] = df.at[entry.name,'NOE_err'][:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e79a17a-f20c-4032-aa96-f4d967ac6d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_missing_expts\n",
      "0    90\n",
      "1     2\n",
      "2     2\n",
      "dtype: int64\n",
      "updating nans in 6470 600 R1\n",
      "fixing zero in 5839 600\n",
      "updating nans in 7035 800 R1\n",
      "updating nans in 7036 800 R1\n",
      "updating nans in 17018 500 R1\n",
      "fixing zero in 18260 600\n",
      "fixing zero in 19335 600\n",
      "fixing zero in 51230 750\n",
      "updating nans in 4689 500 R2\n",
      "updating nans in 6470 600 R2\n",
      "updating nans in 7035 800 R2\n",
      "updating nans in 7036 800 R2\n",
      "updating nans in 17018 500 R2\n",
      "fixing zero in 17246 500\n",
      "fixing zero in 18260 600\n",
      "fixing zero in 51087 850\n",
      "updating nans in 4689 500 NOE\n",
      "updating nans in 6470 600 NOE\n",
      "fixing zero in 6758 600\n",
      "updating nans in 17018 500 NOE\n",
      "fixing zero in 17246 500\n",
      "updating nans in 18306 700 NOE\n",
      "fixing zero in 19189 600\n",
      "updating nans in 19356 600 NOE\n",
      "updating nans in 36171 800 NOE\n"
     ]
    }
   ],
   "source": [
    "def find_any_missing(row):\n",
    "    n_missing_expts = 0\n",
    "    if row['T1_expt_index'] == -1:\n",
    "        n_missing_expts +=1\n",
    "    if row['T2_expt_index'] == -1:\n",
    "        n_missing_expts +=1\n",
    "    if row['NOE_expt_index'] == -1 :\n",
    "        n_missing_expts +=1\n",
    "        \n",
    "    return n_missing_expts\n",
    "\n",
    "#Remove any fields that don't have all 3 expts\n",
    "\n",
    "df['n_missing_expts'] = df.apply(lambda row: find_any_missing(row), axis=1)\n",
    "print(df.groupby('n_missing_expts').size())\n",
    "df['seq_len'] = [len(x) for x in df['sequence']]\n",
    "\n",
    "df = df.loc[df.n_missing_expts==0]\n",
    "\n",
    "#Correct 0 and NaN uncertainties\n",
    "\n",
    "def fix_errs(row, dat_type):\n",
    "    multiplier={'R1': 0.1, 'R2': 0.05,'NOE': 0.05}\n",
    "    dat = row[dat_type+'_err'].copy()\n",
    "    \n",
    "    if np.isnan(dat).all():\n",
    "        print('updating nans in', row['entry_ID'], row['field_strength'], dat_type)\n",
    "        return multiplier[dat_type] * np.abs(row[dat_type])\n",
    "    \n",
    "    elif np.any(dat==0):\n",
    "        print('fixing zero in', row['entry_ID'], row['field_strength'])\n",
    "        nonzeros = dat[np.where(dat>0)]\n",
    "        dat[dat==0] = np.min(nonzeros)\n",
    "        return np.abs(dat)\n",
    "    else:\n",
    "        return np.abs(row[dat_type+'_err'])\n",
    "\n",
    "for dat_type in ['R1','R2','NOE']:\n",
    "    df[dat_type+'_err'] = df.apply(lambda row: fix_errs(row, dat_type), axis=1)\n",
    "\n",
    "df.to_json('BMRB_subset_RelaxDB_20jan2025.json.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "299d1be7-82b5-4ee2-a4f5-da136a65a5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4267 600,750,500\n",
      "5330 500,600\n",
      "5518 500,600,750\n",
      "5687 500,600\n",
      "5841 500,600\n",
      "6838 500,600,800\n",
      "15445 500,600\n",
      "16392 500,600\n",
      "19127 500,750\n",
      "19153 600,900\n",
      "27011 600,850,950\n",
      "27194 500,700\n",
      "27888 600,850\n",
      "50233 600,750\n",
      "51230 600,750\n",
      "51416 600,800\n",
      "4267 500,600,750\n",
      "4390 500\n",
      "4689 500\n",
      "4762 750\n",
      "5154 500\n",
      "5330 500,600\n",
      "5518 500,600,750\n",
      "5687 500,600\n",
      "5762 800\n",
      "5839 600\n",
      "5841 500,600\n",
      "5991 500\n",
      "5995 600\n",
      "6470 600\n",
      "6758 600\n",
      "6838 500,600,800\n",
      "7035 800\n",
      "7036 800\n",
      "7056 600\n",
      "7432 600\n",
      "11080 500\n",
      "15255 600\n",
      "15445 500,600\n",
      "15451 500\n",
      "15521 500\n",
      "15795 500\n",
      "16234 600\n",
      "16392 500,600\n",
      "16426 600\n",
      "16737 600\n",
      "17018 500\n",
      "17246 500\n",
      "17266 600\n",
      "17306 600\n",
      "17701 600\n",
      "17783 600\n",
      "17881 600\n",
      "18092 600\n",
      "18257 500\n",
      "18260 600\n",
      "18306 700\n",
      "18380 600\n",
      "18477 600\n",
      "18758 400\n",
      "18772 600\n",
      "18773 600\n",
      "18903 500\n",
      "19127 500,750\n",
      "19153 600,900\n",
      "19189 600\n",
      "19335 600\n",
      "19356 600\n",
      "25013 800\n",
      "25636 600\n",
      "26513 600\n",
      "26723 600\n",
      "27011 600,850,950\n",
      "27194 500,700\n",
      "27888 600,850\n",
      "28132 850\n",
      "30523 600\n",
      "34545 700\n",
      "36171 800\n",
      "50020 500\n",
      "50233 600,750\n",
      "50332 600\n",
      "50410 700\n",
      "50734 500\n",
      "51087 850\n",
      "51230 600,750\n",
      "51416 600,800\n"
     ]
    }
   ],
   "source": [
    "# List all the fields for each\n",
    "tmp = df.groupby('entry_ID')['field_strength'].apply(list)\n",
    "\n",
    "for x in tmp.index:\n",
    "    if len(tmp[x])>1:\n",
    "        print(x, ','.join([\"%d\"% y for y in tmp[x]]))\n",
    "        \n",
    "for x in tmp.index:\n",
    "    print(x, ','.join([\"%d\"% y for y in sort(tmp[x])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256c9f8-ec39-49d5-87a4-4894a2264818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
